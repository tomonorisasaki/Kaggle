{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## AMPÂ® - Parkinson's Disease Progression Prediction - Baseline","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup","metadata":{}},{"cell_type":"code","source":"import sys\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\ndataset_directory = Path('/kaggle/input/amp-parkinsons-disease-progression-prediction')\nsys.path.append(dataset_directory)\nimport amp_pd_peptide","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T01:46:23.080700Z","iopub.execute_input":"2023-04-17T01:46:23.081018Z","iopub.status.idle":"2023-04-17T01:46:23.185034Z","shell.execute_reply.started":"2023-04-17T01:46:23.080984Z","shell.execute_reply":"2023-04-17T01:46:23.184008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_clinical_data = pd.read_csv(dataset_directory / 'train_clinical_data.csv')\nprint(f'Train Clinical Data Shape: {df_train_clinical_data.shape} - Memory Usage: {df_train_clinical_data.memory_usage().sum() / 1024 ** 2:.2f} MB')\n\npatient_count = df_train_clinical_data['patient_id'].nunique()\nvisit_count_mean = df_train_clinical_data.groupby('patient_id')['visit_month'].count().mean()\nprint(f'Patient Count: {patient_count} - Mean Visit Count: {visit_count_mean:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:23.187148Z","iopub.execute_input":"2023-04-17T01:46:23.187511Z","iopub.status.idle":"2023-04-17T01:46:23.232403Z","shell.execute_reply.started":"2023-04-17T01:46:23.187474Z","shell.execute_reply":"2023-04-17T01:46:23.231352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_supplemental_clinical_data = pd.read_csv(dataset_directory / 'supplemental_clinical_data.csv')\nprint(f'Supplemental Clinical Data Shape: {df_supplemental_clinical_data.shape} - Memory Usage: {df_supplemental_clinical_data.memory_usage().sum() / 1024 ** 2:.2f} MB')\n\npatient_count = df_supplemental_clinical_data['patient_id'].nunique()\nvisit_count_mean = df_supplemental_clinical_data.groupby('patient_id')['visit_month'].count().mean()\nprint(f'Patient Count: {patient_count} - Mean Visit Count: {visit_count_mean:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:23.233542Z","iopub.execute_input":"2023-04-17T01:46:23.233850Z","iopub.status.idle":"2023-04-17T01:46:23.255387Z","shell.execute_reply.started":"2023-04-17T01:46:23.233813Z","shell.execute_reply":"2023-04-17T01:46:23.254445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Evaluation\n\nThe problem is predicting `updrs_1`, `updrs_2`, `updrs_3` and `updrs_4` values at a given `visit_month` and potential **6**, **12** and **24** month visits after the current `visit_month`.\n\nPredictions are evaluated on symmetric mean absolute percentage error (SMAPE) + 1.","metadata":{}},{"cell_type":"code","source":"def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n\n    \"\"\"\n    Calculate symmetric mean absolute percentage error from given ground-truth and predictions\n    \n    Parameters\n    ----------\n    y_true: array-like of shape (n_samples)\n        Array of ground-truth values\n        \n    y_pred: array-like of shape (n_samples)\n        Array of prediction values\n        \n    Returns\n    -------\n    smape: float\n        Symmetric mean absolute percentage error\n    \"\"\"\n\n    smape = 100 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n\n    return smape\n\n\ndef score(df, target_columns, prediction_columns):\n    \n    \"\"\"\n    Concatenate targets and prediction into a single array and calculate SMAPE + 1\n    \n    Parameters\n    ----------\n    target_columns: list of shape (4)\n        Array of target column names\n        \n    prediction_columns: list of shape (4)\n        Array of prediction column names\n        \n    Returns\n    -------\n    score: float\n        Symmetric mean absolute percentage error\n    \"\"\"\n    \n    y_true = []\n    y_pred = []\n    \n    for target_column, prediction_column in zip(target_columns, prediction_columns):\n        target_idx = df[target_column].notna()\n        y_true.append(df.loc[target_idx, target_column].values + 1)\n        y_pred.append(df.loc[target_idx, prediction_column].values + 1)\n        \n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n        \n    score = symmetric_mean_absolute_percentage_error(\n        y_true=y_true,\n        y_pred=y_pred\n    )\n    \n    return score\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:23.270253Z","iopub.execute_input":"2023-04-17T01:46:23.270659Z","iopub.status.idle":"2023-04-17T01:46:23.280842Z","shell.execute_reply.started":"2023-04-17T01:46:23.270622Z","shell.execute_reply":"2023-04-17T01:46:23.279417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Baselines\n\nMedian values at each visit month is a strong baseline since this kind of forecasting problems are hard. Visit month median values of `updrs_1` are calculated on clinical data and median values of `updrs_2`, `updrs_3`, `updrs_4` are calculated on clinical and supplemental data.\n\nWhen clinical and supplemental data are concatenated, different `visit_month` values (5) exist on the baseline table. Unseen `visit_month` values also exist in hidden test set which will be handled accordingly.\n\nDefault median values of visit months have a flaw. Median updrs values might decrease as `visit_month` increases since dataset is not large enough. A baseline like that might overfit to training set and generalize poorly. Replacing median values with expanding window max values increases validation and leaderboard scores.","metadata":{}},{"cell_type":"code","source":"target_columns_clinical_data = ['updrs_1']\ntarget_columns_clinical_and_supplemental_data = ['updrs_2', 'updrs_3', 'updrs_4']\n\ntarget_visit_month_medians_clinical_data = df_train_clinical_data.groupby('visit_month')[target_columns_clinical_data].median()\ntarget_visit_month_medians_clinical_and_supplemental_data = pd.concat((\n    df_train_clinical_data,\n    df_supplemental_clinical_data\n), axis=0).groupby('visit_month')[target_columns_clinical_and_supplemental_data].median()\n\n# Drop 5th month visit that is coming from the supplemental clinical data\ntarget_visit_month_medians_clinical_and_supplemental_data = target_visit_month_medians_clinical_and_supplemental_data.drop(5)\n\n# Concatenate visit_month medians of targets\ntarget_visit_month_medians = pd.concat((\n    target_visit_month_medians_clinical_data,\n    target_visit_month_medians_clinical_and_supplemental_data\n), axis=1, ignore_index=False)\n\n# Replace expanding window max of updrs values with current updrs values\ntarget_visit_month_medians = target_visit_month_medians.expanding(min_periods=1).max()\ntarget_visit_month_medians","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:23.282552Z","iopub.execute_input":"2023-04-17T01:46:23.282910Z","iopub.status.idle":"2023-04-17T01:46:23.336174Z","shell.execute_reply.started":"2023-04-17T01:46:23.282874Z","shell.execute_reply":"2023-04-17T01:46:23.334798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Validation\n\n* Medians of `visit_month` groups calculated on train clinical data\n  * `updrs_1` OOF: **55.63**\n  * `updrs_2` OOF: **70.51**\n  * `updrs_3` OOF: **70.94**\n  * `updrs_4` OOF: **48.00**\n  * Global OOF: **62.71**\n  * Public LB Score: **57.8** (filled with global target medians)\n  \n* Medians of `visit_month` groups calculated on train + supplemental clinical data\n  * `updrs_1` OOF: **56.16**\n  * `updrs_2` OOF: **70.53**\n  * `updrs_3` OOF: **70.16**\n  * `updrs_4` OOF: **48.00**\n  * Global OOF: **62.65**\n  * Public LB Score: **57.2** (filled with global target medians)\n  \n* Medians of `visit_month` groups calculated on train + supplemental clinical data replaced with expanding window max\n  * `updrs_1` OOF: **56.29**\n  * `updrs_2` OOF: **70.79**\n  * `updrs_3` OOF: **69.19**\n  * `updrs_4` OOF: **48.01**\n  * Global OOF: **62.49**\n  * Public LB Score: **56.4** (filled with global target medians)\n  \n* Medians of `visit_month` groups calculated on train for `updrs_1` and train + supplemental clinical data for `updrs_2`, `updrs_3`, `updrs_4` \n  * `updrs_1` OOF: **55.74**\n  * `updrs_2` OOF: **70.79**\n  * `updrs_3` OOF: **69.19**\n  * `updrs_4` OOF: **48.01**\n  * Global OOF: **62.34**\n  * Public LB Score: **56.3** (filled with closest `visit_month` median)","metadata":{}},{"cell_type":"code","source":"fold_columns = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\ntarget_columns = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n\nfor target_column in target_columns:\n        \n    target_idx = df_train_clinical_data[target_column].notna()\n    df_train = df_train_clinical_data.loc[target_idx]\n    print(f'Target: {target_column} Dataset Shape: {df_train.shape}')\n        \n    df_train_clinical_data.loc[target_idx, f'{target_column}_predictions'] = df_train_clinical_data.loc[target_idx, 'visit_month'].map(target_visit_month_medians[target_column])\n    val_score = score(\n        df=df_train_clinical_data.loc[target_idx],\n        target_columns=[target_column],\n        prediction_columns=[f'{target_column}_predictions']\n    )\n    print(f'Validation SMAPE: {val_score:.4f}\\n')\n    \nglobal_oof_score = score(\n    df=df_train_clinical_data,\n    target_columns=target_columns,\n    prediction_columns=[f'{target_column}_predictions' for target_column in target_columns]\n)\nprint(f'Global OOF SMAPE: {global_oof_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:23.338719Z","iopub.execute_input":"2023-04-17T01:46:23.339545Z","iopub.status.idle":"2023-04-17T01:46:23.369114Z","shell.execute_reply.started":"2023-04-17T01:46:23.339503Z","shell.execute_reply":"2023-04-17T01:46:23.368020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Submission\n\nSince hidden test has unseen `visit_month` values, there will be some missing predictions after mapping the baselines. In order to deal with those cases, closest `visit_month` baseline values are used for filling missing predictions after the map operation.","metadata":{}},{"cell_type":"code","source":"env = amp_pd_peptide.make_env()\ntest_iterator = env.iter_test() \n\nfor (df_test, df_test_peptides, df_test_proteins, df_submission) in test_iterator:\n    \n    df_submission['patient_id'] = df_submission.apply('prediction_id').str.split('_', expand=True)[0].astype(int)\n    df_submission['current_visit_month'] = df_submission.apply('prediction_id').str.split('_', expand=True)[1].astype(int)\n    df_submission['visit_month_offset'] = df_submission.apply('prediction_id').str.split('_', expand=True)[5].astype(int)\n    df_submission['prediction_visit_month'] = df_submission['current_visit_month'] + df_submission['visit_month_offset'].astype(int)\n    df_submission['updrs'] = df_submission.apply('prediction_id').str.split('_', expand=True)[3].astype(int)\n\n    for updrs in range(1, 5):\n        updrs_idx = df_submission['updrs'] == updrs\n        df_submission.loc[updrs_idx, 'rating'] = df_submission.loc[updrs_idx, 'prediction_visit_month'].map(target_visit_month_medians[f'updrs_{updrs}'])\n        \n        missing_idx = df_submission['rating'].isnull()\n        # Iterate over missing prediction rows after mapping the baselines\n        for idx, row in df_submission[updrs_idx & missing_idx].iterrows():\n            # Find the closest visit_month value from the baselines table\n            target_visit_month_median_idx = np.argmin(np.abs(target_visit_month_medians.index - row['prediction_visit_month']))\n            # Write the closest visit_month value to the unseen visit_month\n            df_submission.loc[idx, 'rating'] = target_visit_month_medians.iloc[target_visit_month_median_idx, updrs - 1]\n    \n    df_submission = df_submission.loc[:, ['prediction_id', 'rating']]\n    env.predict(df_submission)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:23.370872Z","iopub.execute_input":"2023-04-17T01:46:23.371245Z","iopub.status.idle":"2023-04-17T01:46:23.448682Z","shell.execute_reply.started":"2023-04-17T01:46:23.371209Z","shell.execute_reply":"2023-04-17T01:46:23.447565Z"},"trusted":true},"execution_count":null,"outputs":[]}]}